{
  "best_metric": 39.160831451416016,
  "best_model_checkpoint": "/home/ubuntu/fs1/save/checkpoint-292",
  "epoch": 2.0,
  "eval_steps": 4,
  "global_step": 300,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006666666666666667,
      "grad_norm": 32779.3515625,
      "learning_rate": 8e-06,
      "loss": 792.0,
      "step": 1
    },
    {
      "epoch": 0.013333333333333334,
      "grad_norm": 29753.37109375,
      "learning_rate": 8e-06,
      "loss": 804.0,
      "step": 2
    },
    {
      "epoch": 0.02,
      "grad_norm": 57821.2734375,
      "learning_rate": 8e-06,
      "loss": 760.0,
      "step": 3
    },
    {
      "epoch": 0.02666666666666667,
      "grad_norm": 22238.390625,
      "learning_rate": 8e-06,
      "loss": 536.0,
      "step": 4
    },
    {
      "epoch": 0.02666666666666667,
      "eval_loss": 453.0400085449219,
      "eval_runtime": 13.5684,
      "eval_samples_per_second": 44.22,
      "eval_steps_per_second": 2.801,
      "step": 4
    },
    {
      "epoch": 0.03333333333333333,
      "grad_norm": 18338.544921875,
      "learning_rate": 8e-06,
      "loss": 552.0,
      "step": 5
    },
    {
      "epoch": 0.04,
      "grad_norm": 9911.90625,
      "learning_rate": 8e-06,
      "loss": 432.0,
      "step": 6
    },
    {
      "epoch": 0.04666666666666667,
      "grad_norm": 4207.64208984375,
      "learning_rate": 8e-06,
      "loss": 219.0,
      "step": 7
    },
    {
      "epoch": 0.05333333333333334,
      "grad_norm": 3844.037353515625,
      "learning_rate": 8e-06,
      "loss": 200.0,
      "step": 8
    },
    {
      "epoch": 0.05333333333333334,
      "eval_loss": 199.69332885742188,
      "eval_runtime": 14.0384,
      "eval_samples_per_second": 42.74,
      "eval_steps_per_second": 2.707,
      "step": 8
    },
    {
      "epoch": 0.06,
      "grad_norm": 4631.11376953125,
      "learning_rate": 8e-06,
      "loss": 140.0,
      "step": 9
    },
    {
      "epoch": 0.06666666666666667,
      "grad_norm": 3507.26025390625,
      "learning_rate": 8e-06,
      "loss": 143.0,
      "step": 10
    },
    {
      "epoch": 0.07333333333333333,
      "grad_norm": 3709.6435546875,
      "learning_rate": 8e-06,
      "loss": 83.5,
      "step": 11
    },
    {
      "epoch": 0.08,
      "grad_norm": 9619.505859375,
      "learning_rate": 8e-06,
      "loss": 222.0,
      "step": 12
    },
    {
      "epoch": 0.08,
      "eval_loss": 136.45333862304688,
      "eval_runtime": 14.0135,
      "eval_samples_per_second": 42.816,
      "eval_steps_per_second": 2.712,
      "step": 12
    },
    {
      "epoch": 0.08666666666666667,
      "grad_norm": 2482.167236328125,
      "learning_rate": 8e-06,
      "loss": 139.0,
      "step": 13
    },
    {
      "epoch": 0.09333333333333334,
      "grad_norm": 2845.99609375,
      "learning_rate": 8e-06,
      "loss": 172.0,
      "step": 14
    },
    {
      "epoch": 0.1,
      "grad_norm": 2618.594482421875,
      "learning_rate": 8e-06,
      "loss": 129.0,
      "step": 15
    },
    {
      "epoch": 0.10666666666666667,
      "grad_norm": 1752.12353515625,
      "learning_rate": 8e-06,
      "loss": 134.0,
      "step": 16
    },
    {
      "epoch": 0.10666666666666667,
      "eval_loss": 110.336669921875,
      "eval_runtime": 13.8508,
      "eval_samples_per_second": 43.319,
      "eval_steps_per_second": 2.744,
      "step": 16
    },
    {
      "epoch": 0.11333333333333333,
      "grad_norm": 1462.4166259765625,
      "learning_rate": 8e-06,
      "loss": 91.5,
      "step": 17
    },
    {
      "epoch": 0.12,
      "grad_norm": 1566.36376953125,
      "learning_rate": 8e-06,
      "loss": 82.0,
      "step": 18
    },
    {
      "epoch": 0.12666666666666668,
      "grad_norm": 1387.9827880859375,
      "learning_rate": 8e-06,
      "loss": 90.0,
      "step": 19
    },
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 1668.882080078125,
      "learning_rate": 8e-06,
      "loss": 104.5,
      "step": 20
    },
    {
      "epoch": 0.13333333333333333,
      "eval_loss": 94.9800033569336,
      "eval_runtime": 13.8548,
      "eval_samples_per_second": 43.306,
      "eval_steps_per_second": 2.743,
      "step": 20
    },
    {
      "epoch": 0.14,
      "grad_norm": 1613.997314453125,
      "learning_rate": 8e-06,
      "loss": 92.5,
      "step": 21
    },
    {
      "epoch": 0.14666666666666667,
      "grad_norm": 1137.32470703125,
      "learning_rate": 8e-06,
      "loss": 63.5,
      "step": 22
    },
    {
      "epoch": 0.15333333333333332,
      "grad_norm": 1374.3853759765625,
      "learning_rate": 8e-06,
      "loss": 116.0,
      "step": 23
    },
    {
      "epoch": 0.16,
      "grad_norm": 1175.6053466796875,
      "learning_rate": 8e-06,
      "loss": 68.0,
      "step": 24
    },
    {
      "epoch": 0.16,
      "eval_loss": 84.45333099365234,
      "eval_runtime": 14.0813,
      "eval_samples_per_second": 42.61,
      "eval_steps_per_second": 2.699,
      "step": 24
    },
    {
      "epoch": 0.16666666666666666,
      "grad_norm": 1659.7476806640625,
      "learning_rate": 8e-06,
      "loss": 85.5,
      "step": 25
    },
    {
      "epoch": 0.17333333333333334,
      "grad_norm": 851.2265625,
      "learning_rate": 8e-06,
      "loss": 36.75,
      "step": 26
    },
    {
      "epoch": 0.18,
      "grad_norm": 1715.894287109375,
      "learning_rate": 8e-06,
      "loss": 83.5,
      "step": 27
    },
    {
      "epoch": 0.18666666666666668,
      "grad_norm": 1023.380615234375,
      "learning_rate": 8e-06,
      "loss": 49.75,
      "step": 28
    },
    {
      "epoch": 0.18666666666666668,
      "eval_loss": 77.32666778564453,
      "eval_runtime": 14.1031,
      "eval_samples_per_second": 42.544,
      "eval_steps_per_second": 2.694,
      "step": 28
    },
    {
      "epoch": 0.19333333333333333,
      "grad_norm": 854.1201171875,
      "learning_rate": 8e-06,
      "loss": 47.75,
      "step": 29
    },
    {
      "epoch": 0.2,
      "grad_norm": 953.47021484375,
      "learning_rate": 8e-06,
      "loss": 49.5,
      "step": 30
    },
    {
      "epoch": 0.20666666666666667,
      "grad_norm": 1947.322021484375,
      "learning_rate": 8e-06,
      "loss": 120.0,
      "step": 31
    },
    {
      "epoch": 0.21333333333333335,
      "grad_norm": 815.6732177734375,
      "learning_rate": 8e-06,
      "loss": 34.5,
      "step": 32
    },
    {
      "epoch": 0.21333333333333335,
      "eval_loss": 72.8066635131836,
      "eval_runtime": 14.2039,
      "eval_samples_per_second": 42.242,
      "eval_steps_per_second": 2.675,
      "step": 32
    },
    {
      "epoch": 0.22,
      "grad_norm": 1355.3072509765625,
      "learning_rate": 8e-06,
      "loss": 82.0,
      "step": 33
    },
    {
      "epoch": 0.22666666666666666,
      "grad_norm": 1092.9810791015625,
      "learning_rate": 8e-06,
      "loss": 49.25,
      "step": 34
    },
    {
      "epoch": 0.23333333333333334,
      "grad_norm": 877.848388671875,
      "learning_rate": 8e-06,
      "loss": 53.75,
      "step": 35
    },
    {
      "epoch": 0.24,
      "grad_norm": 661.1846313476562,
      "learning_rate": 8e-06,
      "loss": 44.75,
      "step": 36
    },
    {
      "epoch": 0.24,
      "eval_loss": 69.50666809082031,
      "eval_runtime": 13.9873,
      "eval_samples_per_second": 42.896,
      "eval_steps_per_second": 2.717,
      "step": 36
    },
    {
      "epoch": 0.24666666666666667,
      "grad_norm": 1483.7938232421875,
      "learning_rate": 8e-06,
      "loss": 106.5,
      "step": 37
    },
    {
      "epoch": 0.25333333333333335,
      "grad_norm": 732.912353515625,
      "learning_rate": 8e-06,
      "loss": 51.5,
      "step": 38
    },
    {
      "epoch": 0.26,
      "grad_norm": 1127.5550537109375,
      "learning_rate": 8e-06,
      "loss": 52.25,
      "step": 39
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 1452.14208984375,
      "learning_rate": 8e-06,
      "loss": 119.0,
      "step": 40
    },
    {
      "epoch": 0.26666666666666666,
      "eval_loss": 65.49666595458984,
      "eval_runtime": 14.0187,
      "eval_samples_per_second": 42.8,
      "eval_steps_per_second": 2.711,
      "step": 40
    },
    {
      "epoch": 0.2733333333333333,
      "grad_norm": 4235.25,
      "learning_rate": 8e-06,
      "loss": 206.0,
      "step": 41
    },
    {
      "epoch": 0.28,
      "grad_norm": 1228.0159912109375,
      "learning_rate": 8e-06,
      "loss": 37.0,
      "step": 42
    },
    {
      "epoch": 0.2866666666666667,
      "grad_norm": 966.0263671875,
      "learning_rate": 8e-06,
      "loss": 63.25,
      "step": 43
    },
    {
      "epoch": 0.29333333333333333,
      "grad_norm": 1351.7584228515625,
      "learning_rate": 8e-06,
      "loss": 113.0,
      "step": 44
    },
    {
      "epoch": 0.29333333333333333,
      "eval_loss": 62.86166763305664,
      "eval_runtime": 14.1442,
      "eval_samples_per_second": 42.42,
      "eval_steps_per_second": 2.687,
      "step": 44
    },
    {
      "epoch": 0.3,
      "grad_norm": 1828.586181640625,
      "learning_rate": 8e-06,
      "loss": 129.0,
      "step": 45
    },
    {
      "epoch": 0.30666666666666664,
      "grad_norm": 1867.8607177734375,
      "learning_rate": 8e-06,
      "loss": 109.0,
      "step": 46
    },
    {
      "epoch": 0.31333333333333335,
      "grad_norm": 5124.9931640625,
      "learning_rate": 8e-06,
      "loss": 125.5,
      "step": 47
    },
    {
      "epoch": 0.32,
      "grad_norm": 1612.2332763671875,
      "learning_rate": 8e-06,
      "loss": 121.5,
      "step": 48
    },
    {
      "epoch": 0.32,
      "eval_loss": 61.880001068115234,
      "eval_runtime": 13.903,
      "eval_samples_per_second": 43.156,
      "eval_steps_per_second": 2.733,
      "step": 48
    },
    {
      "epoch": 0.32666666666666666,
      "grad_norm": 1049.9595947265625,
      "learning_rate": 8e-06,
      "loss": 64.5,
      "step": 49
    },
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 941.875,
      "learning_rate": 8e-06,
      "loss": 72.0,
      "step": 50
    },
    {
      "epoch": 0.34,
      "grad_norm": 1485.4212646484375,
      "learning_rate": 8e-06,
      "loss": 73.0,
      "step": 51
    },
    {
      "epoch": 0.3466666666666667,
      "grad_norm": 2511.933349609375,
      "learning_rate": 8e-06,
      "loss": 76.0,
      "step": 52
    },
    {
      "epoch": 0.3466666666666667,
      "eval_loss": 60.0533332824707,
      "eval_runtime": 14.2246,
      "eval_samples_per_second": 42.18,
      "eval_steps_per_second": 2.671,
      "step": 52
    },
    {
      "epoch": 0.35333333333333333,
      "grad_norm": 1632.90966796875,
      "learning_rate": 8e-06,
      "loss": 52.5,
      "step": 53
    },
    {
      "epoch": 0.36,
      "grad_norm": 832.832763671875,
      "learning_rate": 8e-06,
      "loss": 45.5,
      "step": 54
    },
    {
      "epoch": 0.36666666666666664,
      "grad_norm": 575.9757690429688,
      "learning_rate": 8e-06,
      "loss": 26.5,
      "step": 55
    },
    {
      "epoch": 0.37333333333333335,
      "grad_norm": 1098.32568359375,
      "learning_rate": 8e-06,
      "loss": 93.0,
      "step": 56
    },
    {
      "epoch": 0.37333333333333335,
      "eval_loss": 58.845001220703125,
      "eval_runtime": 14.0717,
      "eval_samples_per_second": 42.639,
      "eval_steps_per_second": 2.7,
      "step": 56
    },
    {
      "epoch": 0.38,
      "grad_norm": 882.991943359375,
      "learning_rate": 8e-06,
      "loss": 64.5,
      "step": 57
    },
    {
      "epoch": 0.38666666666666666,
      "grad_norm": 943.2865600585938,
      "learning_rate": 8e-06,
      "loss": 72.0,
      "step": 58
    },
    {
      "epoch": 0.3933333333333333,
      "grad_norm": 538.955810546875,
      "learning_rate": 8e-06,
      "loss": 24.875,
      "step": 59
    },
    {
      "epoch": 0.4,
      "grad_norm": 592.6442260742188,
      "learning_rate": 8e-06,
      "loss": 28.75,
      "step": 60
    },
    {
      "epoch": 0.4,
      "eval_loss": 57.79999923706055,
      "eval_runtime": 14.0042,
      "eval_samples_per_second": 42.844,
      "eval_steps_per_second": 2.713,
      "step": 60
    },
    {
      "epoch": 0.4066666666666667,
      "grad_norm": 1032.2822265625,
      "learning_rate": 8e-06,
      "loss": 60.5,
      "step": 61
    },
    {
      "epoch": 0.41333333333333333,
      "grad_norm": 1342.850341796875,
      "learning_rate": 8e-06,
      "loss": 76.0,
      "step": 62
    },
    {
      "epoch": 0.42,
      "grad_norm": 870.046142578125,
      "learning_rate": 8e-06,
      "loss": 39.25,
      "step": 63
    },
    {
      "epoch": 0.4266666666666667,
      "grad_norm": 770.9419555664062,
      "learning_rate": 8e-06,
      "loss": 56.75,
      "step": 64
    },
    {
      "epoch": 0.4266666666666667,
      "eval_loss": 56.55500030517578,
      "eval_runtime": 13.8799,
      "eval_samples_per_second": 43.228,
      "eval_steps_per_second": 2.738,
      "step": 64
    },
    {
      "epoch": 0.43333333333333335,
      "grad_norm": 977.6295166015625,
      "learning_rate": 8e-06,
      "loss": 53.5,
      "step": 65
    },
    {
      "epoch": 0.44,
      "grad_norm": 776.9673461914062,
      "learning_rate": 8e-06,
      "loss": 53.0,
      "step": 66
    },
    {
      "epoch": 0.44666666666666666,
      "grad_norm": 558.34521484375,
      "learning_rate": 8e-06,
      "loss": 31.875,
      "step": 67
    },
    {
      "epoch": 0.4533333333333333,
      "grad_norm": 1892.319580078125,
      "learning_rate": 8e-06,
      "loss": 83.0,
      "step": 68
    },
    {
      "epoch": 0.4533333333333333,
      "eval_loss": 56.97999954223633,
      "eval_runtime": 14.151,
      "eval_samples_per_second": 42.4,
      "eval_steps_per_second": 2.685,
      "step": 68
    },
    {
      "epoch": 0.46,
      "grad_norm": 1215.9652099609375,
      "learning_rate": 8e-06,
      "loss": 76.0,
      "step": 69
    },
    {
      "epoch": 0.4666666666666667,
      "grad_norm": 1269.7359619140625,
      "learning_rate": 8e-06,
      "loss": 45.25,
      "step": 70
    },
    {
      "epoch": 0.47333333333333333,
      "grad_norm": 890.072021484375,
      "learning_rate": 8e-06,
      "loss": 64.5,
      "step": 71
    },
    {
      "epoch": 0.48,
      "grad_norm": 1051.363525390625,
      "learning_rate": 8e-06,
      "loss": 59.0,
      "step": 72
    },
    {
      "epoch": 0.48,
      "eval_loss": 54.95500183105469,
      "eval_runtime": 14.0651,
      "eval_samples_per_second": 42.659,
      "eval_steps_per_second": 2.702,
      "step": 72
    },
    {
      "epoch": 0.4866666666666667,
      "grad_norm": 713.9137573242188,
      "learning_rate": 8e-06,
      "loss": 37.75,
      "step": 73
    },
    {
      "epoch": 0.49333333333333335,
      "grad_norm": 704.7202758789062,
      "learning_rate": 8e-06,
      "loss": 37.75,
      "step": 74
    },
    {
      "epoch": 0.5,
      "grad_norm": 683.6862182617188,
      "learning_rate": 8e-06,
      "loss": 36.0,
      "step": 75
    },
    {
      "epoch": 0.5066666666666667,
      "grad_norm": 1002.8270874023438,
      "learning_rate": 8e-06,
      "loss": 22.75,
      "step": 76
    },
    {
      "epoch": 0.5066666666666667,
      "eval_loss": 53.400001525878906,
      "eval_runtime": 14.0427,
      "eval_samples_per_second": 42.727,
      "eval_steps_per_second": 2.706,
      "step": 76
    },
    {
      "epoch": 0.5133333333333333,
      "grad_norm": 729.3182373046875,
      "learning_rate": 8e-06,
      "loss": 45.0,
      "step": 77
    },
    {
      "epoch": 0.52,
      "grad_norm": 885.0792846679688,
      "learning_rate": 8e-06,
      "loss": 55.5,
      "step": 78
    },
    {
      "epoch": 0.5266666666666666,
      "grad_norm": 1001.1968383789062,
      "learning_rate": 8e-06,
      "loss": 90.0,
      "step": 79
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 538.60595703125,
      "learning_rate": 8e-06,
      "loss": 29.125,
      "step": 80
    },
    {
      "epoch": 0.5333333333333333,
      "eval_loss": 52.961666107177734,
      "eval_runtime": 13.9298,
      "eval_samples_per_second": 43.073,
      "eval_steps_per_second": 2.728,
      "step": 80
    },
    {
      "epoch": 0.54,
      "grad_norm": 763.1348266601562,
      "learning_rate": 8e-06,
      "loss": 56.75,
      "step": 81
    },
    {
      "epoch": 0.5466666666666666,
      "grad_norm": 1208.9512939453125,
      "learning_rate": 8e-06,
      "loss": 47.75,
      "step": 82
    },
    {
      "epoch": 0.5533333333333333,
      "grad_norm": 1916.377685546875,
      "learning_rate": 8e-06,
      "loss": 83.0,
      "step": 83
    },
    {
      "epoch": 0.56,
      "grad_norm": 549.0750122070312,
      "learning_rate": 8e-06,
      "loss": 32.25,
      "step": 84
    },
    {
      "epoch": 0.56,
      "eval_loss": 52.595001220703125,
      "eval_runtime": 13.9698,
      "eval_samples_per_second": 42.95,
      "eval_steps_per_second": 2.72,
      "step": 84
    },
    {
      "epoch": 0.5666666666666667,
      "grad_norm": 696.4740600585938,
      "learning_rate": 8e-06,
      "loss": 29.375,
      "step": 85
    },
    {
      "epoch": 0.5733333333333334,
      "grad_norm": 685.5492553710938,
      "learning_rate": 8e-06,
      "loss": 42.25,
      "step": 86
    },
    {
      "epoch": 0.58,
      "grad_norm": 1004.3592529296875,
      "learning_rate": 8e-06,
      "loss": 51.75,
      "step": 87
    },
    {
      "epoch": 0.5866666666666667,
      "grad_norm": 1067.2840576171875,
      "learning_rate": 8e-06,
      "loss": 40.5,
      "step": 88
    },
    {
      "epoch": 0.5866666666666667,
      "eval_loss": 52.12333297729492,
      "eval_runtime": 13.797,
      "eval_samples_per_second": 43.488,
      "eval_steps_per_second": 2.754,
      "step": 88
    },
    {
      "epoch": 0.5933333333333334,
      "grad_norm": 759.4949340820312,
      "learning_rate": 8e-06,
      "loss": 41.0,
      "step": 89
    },
    {
      "epoch": 0.6,
      "grad_norm": 895.3983764648438,
      "learning_rate": 8e-06,
      "loss": 47.5,
      "step": 90
    },
    {
      "epoch": 0.6066666666666667,
      "grad_norm": 592.9801635742188,
      "learning_rate": 8e-06,
      "loss": 20.25,
      "step": 91
    },
    {
      "epoch": 0.6133333333333333,
      "grad_norm": 492.6416320800781,
      "learning_rate": 8e-06,
      "loss": 31.5,
      "step": 92
    },
    {
      "epoch": 0.6133333333333333,
      "eval_loss": 51.20833206176758,
      "eval_runtime": 13.954,
      "eval_samples_per_second": 42.998,
      "eval_steps_per_second": 2.723,
      "step": 92
    },
    {
      "epoch": 0.62,
      "grad_norm": 602.9441528320312,
      "learning_rate": 8e-06,
      "loss": 34.5,
      "step": 93
    },
    {
      "epoch": 0.6266666666666667,
      "grad_norm": 431.1287841796875,
      "learning_rate": 8e-06,
      "loss": 21.75,
      "step": 94
    },
    {
      "epoch": 0.6333333333333333,
      "grad_norm": 392.9526062011719,
      "learning_rate": 8e-06,
      "loss": 22.125,
      "step": 95
    },
    {
      "epoch": 0.64,
      "grad_norm": 869.9703369140625,
      "learning_rate": 8e-06,
      "loss": 42.5,
      "step": 96
    },
    {
      "epoch": 0.64,
      "eval_loss": 52.1966667175293,
      "eval_runtime": 14.1141,
      "eval_samples_per_second": 42.511,
      "eval_steps_per_second": 2.692,
      "step": 96
    },
    {
      "epoch": 0.6466666666666666,
      "grad_norm": 880.9435424804688,
      "learning_rate": 8e-06,
      "loss": 36.5,
      "step": 97
    },
    {
      "epoch": 0.6533333333333333,
      "grad_norm": 491.2529602050781,
      "learning_rate": 8e-06,
      "loss": 24.5,
      "step": 98
    },
    {
      "epoch": 0.66,
      "grad_norm": 605.4280395507812,
      "learning_rate": 8e-06,
      "loss": 44.0,
      "step": 99
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 581.419677734375,
      "learning_rate": 8e-06,
      "loss": 30.125,
      "step": 100
    },
    {
      "epoch": 0.6666666666666666,
      "eval_loss": 50.38999938964844,
      "eval_runtime": 13.9507,
      "eval_samples_per_second": 43.008,
      "eval_steps_per_second": 2.724,
      "step": 100
    },
    {
      "epoch": 0.6733333333333333,
      "grad_norm": 726.5972290039062,
      "learning_rate": 8e-06,
      "loss": 47.0,
      "step": 101
    },
    {
      "epoch": 0.68,
      "grad_norm": 523.561279296875,
      "learning_rate": 8e-06,
      "loss": 32.0,
      "step": 102
    },
    {
      "epoch": 0.6866666666666666,
      "grad_norm": 751.5860595703125,
      "learning_rate": 8e-06,
      "loss": 60.25,
      "step": 103
    },
    {
      "epoch": 0.6933333333333334,
      "grad_norm": 1266.2744140625,
      "learning_rate": 8e-06,
      "loss": 76.0,
      "step": 104
    },
    {
      "epoch": 0.6933333333333334,
      "eval_loss": 50.098331451416016,
      "eval_runtime": 14.0549,
      "eval_samples_per_second": 42.69,
      "eval_steps_per_second": 2.704,
      "step": 104
    },
    {
      "epoch": 0.7,
      "grad_norm": 915.0067749023438,
      "learning_rate": 8e-06,
      "loss": 43.75,
      "step": 105
    },
    {
      "epoch": 0.7066666666666667,
      "grad_norm": 973.237548828125,
      "learning_rate": 8e-06,
      "loss": 43.5,
      "step": 106
    },
    {
      "epoch": 0.7133333333333334,
      "grad_norm": 652.1881103515625,
      "learning_rate": 8e-06,
      "loss": 43.0,
      "step": 107
    },
    {
      "epoch": 0.72,
      "grad_norm": 1438.4781494140625,
      "learning_rate": 8e-06,
      "loss": 99.5,
      "step": 108
    },
    {
      "epoch": 0.72,
      "eval_loss": 50.060001373291016,
      "eval_runtime": 14.026,
      "eval_samples_per_second": 42.778,
      "eval_steps_per_second": 2.709,
      "step": 108
    },
    {
      "epoch": 0.7266666666666667,
      "grad_norm": 710.859619140625,
      "learning_rate": 8e-06,
      "loss": 28.625,
      "step": 109
    },
    {
      "epoch": 0.7333333333333333,
      "grad_norm": 606.0282592773438,
      "learning_rate": 8e-06,
      "loss": 41.5,
      "step": 110
    },
    {
      "epoch": 0.74,
      "grad_norm": 652.039306640625,
      "learning_rate": 8e-06,
      "loss": 24.75,
      "step": 111
    },
    {
      "epoch": 0.7466666666666667,
      "grad_norm": 652.6957397460938,
      "learning_rate": 8e-06,
      "loss": 44.0,
      "step": 112
    },
    {
      "epoch": 0.7466666666666667,
      "eval_loss": 48.33333206176758,
      "eval_runtime": 13.8647,
      "eval_samples_per_second": 43.275,
      "eval_steps_per_second": 2.741,
      "step": 112
    },
    {
      "epoch": 0.7533333333333333,
      "grad_norm": 395.2167053222656,
      "learning_rate": 8e-06,
      "loss": 23.625,
      "step": 113
    },
    {
      "epoch": 0.76,
      "grad_norm": 1676.4659423828125,
      "learning_rate": 8e-06,
      "loss": 68.5,
      "step": 114
    },
    {
      "epoch": 0.7666666666666667,
      "grad_norm": 1448.0428466796875,
      "learning_rate": 8e-06,
      "loss": 68.5,
      "step": 115
    },
    {
      "epoch": 0.7733333333333333,
      "grad_norm": 665.5802001953125,
      "learning_rate": 8e-06,
      "loss": 44.0,
      "step": 116
    },
    {
      "epoch": 0.7733333333333333,
      "eval_loss": 48.57666778564453,
      "eval_runtime": 14.0527,
      "eval_samples_per_second": 42.697,
      "eval_steps_per_second": 2.704,
      "step": 116
    },
    {
      "epoch": 0.78,
      "grad_norm": 849.9088745117188,
      "learning_rate": 8e-06,
      "loss": 67.5,
      "step": 117
    },
    {
      "epoch": 0.7866666666666666,
      "grad_norm": 821.7429809570312,
      "learning_rate": 8e-06,
      "loss": 48.25,
      "step": 118
    },
    {
      "epoch": 0.7933333333333333,
      "grad_norm": 978.4408569335938,
      "learning_rate": 8e-06,
      "loss": 94.0,
      "step": 119
    },
    {
      "epoch": 0.8,
      "grad_norm": 553.7583618164062,
      "learning_rate": 8e-06,
      "loss": 18.625,
      "step": 120
    },
    {
      "epoch": 0.8,
      "eval_loss": 47.5966682434082,
      "eval_runtime": 13.9476,
      "eval_samples_per_second": 43.018,
      "eval_steps_per_second": 2.724,
      "step": 120
    },
    {
      "epoch": 0.8066666666666666,
      "grad_norm": 1423.643798828125,
      "learning_rate": 8e-06,
      "loss": 62.25,
      "step": 121
    },
    {
      "epoch": 0.8133333333333334,
      "grad_norm": 834.3680419921875,
      "learning_rate": 8e-06,
      "loss": 46.0,
      "step": 122
    },
    {
      "epoch": 0.82,
      "grad_norm": 975.2810668945312,
      "learning_rate": 8e-06,
      "loss": 50.5,
      "step": 123
    },
    {
      "epoch": 0.8266666666666667,
      "grad_norm": 705.2837524414062,
      "learning_rate": 8e-06,
      "loss": 56.75,
      "step": 124
    },
    {
      "epoch": 0.8266666666666667,
      "eval_loss": 47.14500045776367,
      "eval_runtime": 13.8558,
      "eval_samples_per_second": 43.303,
      "eval_steps_per_second": 2.743,
      "step": 124
    },
    {
      "epoch": 0.8333333333333334,
      "grad_norm": 1049.0999755859375,
      "learning_rate": 8e-06,
      "loss": 51.5,
      "step": 125
    },
    {
      "epoch": 0.84,
      "grad_norm": 607.45654296875,
      "learning_rate": 8e-06,
      "loss": 46.0,
      "step": 126
    },
    {
      "epoch": 0.8466666666666667,
      "grad_norm": 5644.4072265625,
      "learning_rate": 8e-06,
      "loss": 162.0,
      "step": 127
    },
    {
      "epoch": 0.8533333333333334,
      "grad_norm": 585.38232421875,
      "learning_rate": 8e-06,
      "loss": 26.125,
      "step": 128
    },
    {
      "epoch": 0.8533333333333334,
      "eval_loss": 46.68000030517578,
      "eval_runtime": 13.9001,
      "eval_samples_per_second": 43.165,
      "eval_steps_per_second": 2.734,
      "step": 128
    },
    {
      "epoch": 0.86,
      "grad_norm": 910.6094360351562,
      "learning_rate": 8e-06,
      "loss": 78.5,
      "step": 129
    },
    {
      "epoch": 0.8666666666666667,
      "grad_norm": 475.65203857421875,
      "learning_rate": 8e-06,
      "loss": 29.0,
      "step": 130
    },
    {
      "epoch": 0.8733333333333333,
      "grad_norm": 373.2415771484375,
      "learning_rate": 8e-06,
      "loss": 16.125,
      "step": 131
    },
    {
      "epoch": 0.88,
      "grad_norm": 746.3110961914062,
      "learning_rate": 8e-06,
      "loss": 25.25,
      "step": 132
    },
    {
      "epoch": 0.88,
      "eval_loss": 47.07833480834961,
      "eval_runtime": 13.8591,
      "eval_samples_per_second": 43.293,
      "eval_steps_per_second": 2.742,
      "step": 132
    },
    {
      "epoch": 0.8866666666666667,
      "grad_norm": 628.326416015625,
      "learning_rate": 8e-06,
      "loss": 39.75,
      "step": 133
    },
    {
      "epoch": 0.8933333333333333,
      "grad_norm": 473.2231750488281,
      "learning_rate": 8e-06,
      "loss": 37.0,
      "step": 134
    },
    {
      "epoch": 0.9,
      "grad_norm": 1288.931884765625,
      "learning_rate": 8e-06,
      "loss": 51.25,
      "step": 135
    },
    {
      "epoch": 0.9066666666666666,
      "grad_norm": 1024.9505615234375,
      "learning_rate": 8e-06,
      "loss": 74.0,
      "step": 136
    },
    {
      "epoch": 0.9066666666666666,
      "eval_loss": 46.63666534423828,
      "eval_runtime": 14.2497,
      "eval_samples_per_second": 42.106,
      "eval_steps_per_second": 2.667,
      "step": 136
    },
    {
      "epoch": 0.9133333333333333,
      "grad_norm": 606.4232177734375,
      "learning_rate": 8e-06,
      "loss": 31.25,
      "step": 137
    },
    {
      "epoch": 0.92,
      "grad_norm": 572.5958251953125,
      "learning_rate": 8e-06,
      "loss": 29.375,
      "step": 138
    },
    {
      "epoch": 0.9266666666666666,
      "grad_norm": 484.6819152832031,
      "learning_rate": 8e-06,
      "loss": 25.625,
      "step": 139
    },
    {
      "epoch": 0.9333333333333333,
      "grad_norm": 668.5614013671875,
      "learning_rate": 8e-06,
      "loss": 40.25,
      "step": 140
    },
    {
      "epoch": 0.9333333333333333,
      "eval_loss": 45.95166778564453,
      "eval_runtime": 14.0286,
      "eval_samples_per_second": 42.77,
      "eval_steps_per_second": 2.709,
      "step": 140
    },
    {
      "epoch": 0.94,
      "grad_norm": 462.3797302246094,
      "learning_rate": 8e-06,
      "loss": 26.625,
      "step": 141
    },
    {
      "epoch": 0.9466666666666667,
      "grad_norm": 440.5837707519531,
      "learning_rate": 8e-06,
      "loss": 26.0,
      "step": 142
    },
    {
      "epoch": 0.9533333333333334,
      "grad_norm": 423.8164978027344,
      "learning_rate": 8e-06,
      "loss": 24.0,
      "step": 143
    },
    {
      "epoch": 0.96,
      "grad_norm": 669.8278198242188,
      "learning_rate": 8e-06,
      "loss": 42.25,
      "step": 144
    },
    {
      "epoch": 0.96,
      "eval_loss": 45.358333587646484,
      "eval_runtime": 14.0625,
      "eval_samples_per_second": 42.667,
      "eval_steps_per_second": 2.702,
      "step": 144
    },
    {
      "epoch": 0.9666666666666667,
      "grad_norm": 481.5414733886719,
      "learning_rate": 8e-06,
      "loss": 34.5,
      "step": 145
    },
    {
      "epoch": 0.9733333333333334,
      "grad_norm": 502.94854736328125,
      "learning_rate": 8e-06,
      "loss": 25.0,
      "step": 146
    },
    {
      "epoch": 0.98,
      "grad_norm": 485.16851806640625,
      "learning_rate": 8e-06,
      "loss": 29.25,
      "step": 147
    },
    {
      "epoch": 0.9866666666666667,
      "grad_norm": 679.12646484375,
      "learning_rate": 8e-06,
      "loss": 62.0,
      "step": 148
    },
    {
      "epoch": 0.9866666666666667,
      "eval_loss": 44.6533317565918,
      "eval_runtime": 13.9815,
      "eval_samples_per_second": 42.914,
      "eval_steps_per_second": 2.718,
      "step": 148
    },
    {
      "epoch": 0.9933333333333333,
      "grad_norm": 1817.1512451171875,
      "learning_rate": 8e-06,
      "loss": 186.0,
      "step": 149
    },
    {
      "epoch": 1.0,
      "grad_norm": 544.7064819335938,
      "learning_rate": 8e-06,
      "loss": 23.625,
      "step": 150
    },
    {
      "epoch": 1.0066666666666666,
      "grad_norm": 369.09814453125,
      "learning_rate": 8e-06,
      "loss": 22.25,
      "step": 151
    },
    {
      "epoch": 1.0133333333333334,
      "grad_norm": 1300.6982421875,
      "learning_rate": 8e-06,
      "loss": 52.25,
      "step": 152
    },
    {
      "epoch": 1.0133333333333334,
      "eval_loss": 45.90833282470703,
      "eval_runtime": 13.9178,
      "eval_samples_per_second": 43.11,
      "eval_steps_per_second": 2.73,
      "step": 152
    },
    {
      "epoch": 1.02,
      "grad_norm": 601.02685546875,
      "learning_rate": 8e-06,
      "loss": 15.125,
      "step": 153
    },
    {
      "epoch": 1.0266666666666666,
      "grad_norm": 323.0839538574219,
      "learning_rate": 8e-06,
      "loss": 13.375,
      "step": 154
    },
    {
      "epoch": 1.0333333333333334,
      "grad_norm": 601.4821166992188,
      "learning_rate": 8e-06,
      "loss": 36.25,
      "step": 155
    },
    {
      "epoch": 1.04,
      "grad_norm": 419.2318420410156,
      "learning_rate": 8e-06,
      "loss": 28.375,
      "step": 156
    },
    {
      "epoch": 1.04,
      "eval_loss": 44.71500015258789,
      "eval_runtime": 13.661,
      "eval_samples_per_second": 43.921,
      "eval_steps_per_second": 2.782,
      "step": 156
    },
    {
      "epoch": 1.0466666666666666,
      "grad_norm": 1481.6290283203125,
      "learning_rate": 8e-06,
      "loss": 69.0,
      "step": 157
    },
    {
      "epoch": 1.0533333333333332,
      "grad_norm": 1066.488037109375,
      "learning_rate": 8e-06,
      "loss": 55.25,
      "step": 158
    },
    {
      "epoch": 1.06,
      "grad_norm": 489.6767272949219,
      "learning_rate": 8e-06,
      "loss": 35.5,
      "step": 159
    },
    {
      "epoch": 1.0666666666666667,
      "grad_norm": 327.1310119628906,
      "learning_rate": 8e-06,
      "loss": 15.5,
      "step": 160
    },
    {
      "epoch": 1.0666666666666667,
      "eval_loss": 44.404998779296875,
      "eval_runtime": 14.0974,
      "eval_samples_per_second": 42.561,
      "eval_steps_per_second": 2.696,
      "step": 160
    },
    {
      "epoch": 1.0733333333333333,
      "grad_norm": 554.251220703125,
      "learning_rate": 8e-06,
      "loss": 26.5,
      "step": 161
    },
    {
      "epoch": 1.08,
      "grad_norm": 414.48785400390625,
      "learning_rate": 8e-06,
      "loss": 28.125,
      "step": 162
    },
    {
      "epoch": 1.0866666666666667,
      "grad_norm": 607.9561157226562,
      "learning_rate": 8e-06,
      "loss": 20.625,
      "step": 163
    },
    {
      "epoch": 1.0933333333333333,
      "grad_norm": 372.53082275390625,
      "learning_rate": 8e-06,
      "loss": 15.6875,
      "step": 164
    },
    {
      "epoch": 1.0933333333333333,
      "eval_loss": 44.25166702270508,
      "eval_runtime": 13.8056,
      "eval_samples_per_second": 43.461,
      "eval_steps_per_second": 2.753,
      "step": 164
    },
    {
      "epoch": 1.1,
      "grad_norm": 684.434326171875,
      "learning_rate": 8e-06,
      "loss": 29.125,
      "step": 165
    },
    {
      "epoch": 1.1066666666666667,
      "grad_norm": 431.96527099609375,
      "learning_rate": 8e-06,
      "loss": 21.875,
      "step": 166
    },
    {
      "epoch": 1.1133333333333333,
      "grad_norm": 422.5954284667969,
      "learning_rate": 8e-06,
      "loss": 22.625,
      "step": 167
    },
    {
      "epoch": 1.12,
      "grad_norm": 498.8108825683594,
      "learning_rate": 8e-06,
      "loss": 25.625,
      "step": 168
    },
    {
      "epoch": 1.12,
      "eval_loss": 43.5533332824707,
      "eval_runtime": 14.2304,
      "eval_samples_per_second": 42.163,
      "eval_steps_per_second": 2.67,
      "step": 168
    },
    {
      "epoch": 1.1266666666666667,
      "grad_norm": 522.801025390625,
      "learning_rate": 8e-06,
      "loss": 43.0,
      "step": 169
    },
    {
      "epoch": 1.1333333333333333,
      "grad_norm": 509.6060791015625,
      "learning_rate": 8e-06,
      "loss": 24.625,
      "step": 170
    },
    {
      "epoch": 1.1400000000000001,
      "grad_norm": 1075.4139404296875,
      "learning_rate": 8e-06,
      "loss": 90.5,
      "step": 171
    },
    {
      "epoch": 1.1466666666666667,
      "grad_norm": 2906.1435546875,
      "learning_rate": 8e-06,
      "loss": 47.0,
      "step": 172
    },
    {
      "epoch": 1.1466666666666667,
      "eval_loss": 44.505001068115234,
      "eval_runtime": 13.7583,
      "eval_samples_per_second": 43.61,
      "eval_steps_per_second": 2.762,
      "step": 172
    },
    {
      "epoch": 1.1533333333333333,
      "grad_norm": 681.147216796875,
      "learning_rate": 8e-06,
      "loss": 36.5,
      "step": 173
    },
    {
      "epoch": 1.16,
      "grad_norm": 550.4264526367188,
      "learning_rate": 8e-06,
      "loss": 47.5,
      "step": 174
    },
    {
      "epoch": 1.1666666666666667,
      "grad_norm": 483.4200134277344,
      "learning_rate": 8e-06,
      "loss": 25.5,
      "step": 175
    },
    {
      "epoch": 1.1733333333333333,
      "grad_norm": 388.86260986328125,
      "learning_rate": 8e-06,
      "loss": 14.6875,
      "step": 176
    },
    {
      "epoch": 1.1733333333333333,
      "eval_loss": 43.21500015258789,
      "eval_runtime": 14.0759,
      "eval_samples_per_second": 42.626,
      "eval_steps_per_second": 2.7,
      "step": 176
    },
    {
      "epoch": 1.18,
      "grad_norm": 399.9316101074219,
      "learning_rate": 8e-06,
      "loss": 18.375,
      "step": 177
    },
    {
      "epoch": 1.1866666666666668,
      "grad_norm": 744.0670166015625,
      "learning_rate": 8e-06,
      "loss": 48.5,
      "step": 178
    },
    {
      "epoch": 1.1933333333333334,
      "grad_norm": 745.4474487304688,
      "learning_rate": 8e-06,
      "loss": 41.25,
      "step": 179
    },
    {
      "epoch": 1.2,
      "grad_norm": 536.2305908203125,
      "learning_rate": 8e-06,
      "loss": 39.25,
      "step": 180
    },
    {
      "epoch": 1.2,
      "eval_loss": 43.45500183105469,
      "eval_runtime": 13.9543,
      "eval_samples_per_second": 42.997,
      "eval_steps_per_second": 2.723,
      "step": 180
    },
    {
      "epoch": 1.2066666666666666,
      "grad_norm": 467.9120178222656,
      "learning_rate": 8e-06,
      "loss": 26.25,
      "step": 181
    },
    {
      "epoch": 1.2133333333333334,
      "grad_norm": 904.8580932617188,
      "learning_rate": 8e-06,
      "loss": 55.75,
      "step": 182
    },
    {
      "epoch": 1.22,
      "grad_norm": 648.4844970703125,
      "learning_rate": 8e-06,
      "loss": 56.0,
      "step": 183
    },
    {
      "epoch": 1.2266666666666666,
      "grad_norm": 464.2870788574219,
      "learning_rate": 8e-06,
      "loss": 28.5,
      "step": 184
    },
    {
      "epoch": 1.2266666666666666,
      "eval_loss": 43.176666259765625,
      "eval_runtime": 13.8831,
      "eval_samples_per_second": 43.218,
      "eval_steps_per_second": 2.737,
      "step": 184
    },
    {
      "epoch": 1.2333333333333334,
      "grad_norm": 415.34173583984375,
      "learning_rate": 8e-06,
      "loss": 27.5,
      "step": 185
    },
    {
      "epoch": 1.24,
      "grad_norm": 1862.97412109375,
      "learning_rate": 8e-06,
      "loss": 49.25,
      "step": 186
    },
    {
      "epoch": 1.2466666666666666,
      "grad_norm": 705.6987915039062,
      "learning_rate": 8e-06,
      "loss": 30.75,
      "step": 187
    },
    {
      "epoch": 1.2533333333333334,
      "grad_norm": 432.16436767578125,
      "learning_rate": 8e-06,
      "loss": 15.8125,
      "step": 188
    },
    {
      "epoch": 1.2533333333333334,
      "eval_loss": 43.0283317565918,
      "eval_runtime": 14.0743,
      "eval_samples_per_second": 42.631,
      "eval_steps_per_second": 2.7,
      "step": 188
    },
    {
      "epoch": 1.26,
      "grad_norm": 536.9072265625,
      "learning_rate": 8e-06,
      "loss": 33.0,
      "step": 189
    },
    {
      "epoch": 1.2666666666666666,
      "grad_norm": 605.61962890625,
      "learning_rate": 8e-06,
      "loss": 29.375,
      "step": 190
    },
    {
      "epoch": 1.2733333333333334,
      "grad_norm": 710.8106689453125,
      "learning_rate": 8e-06,
      "loss": 63.5,
      "step": 191
    },
    {
      "epoch": 1.28,
      "grad_norm": 464.5545349121094,
      "learning_rate": 8e-06,
      "loss": 32.25,
      "step": 192
    },
    {
      "epoch": 1.28,
      "eval_loss": 42.8466682434082,
      "eval_runtime": 14.0085,
      "eval_samples_per_second": 42.831,
      "eval_steps_per_second": 2.713,
      "step": 192
    },
    {
      "epoch": 1.2866666666666666,
      "grad_norm": 1367.9072265625,
      "learning_rate": 8e-06,
      "loss": 73.0,
      "step": 193
    },
    {
      "epoch": 1.2933333333333334,
      "grad_norm": 762.5653076171875,
      "learning_rate": 8e-06,
      "loss": 25.625,
      "step": 194
    },
    {
      "epoch": 1.3,
      "grad_norm": 614.8763427734375,
      "learning_rate": 8e-06,
      "loss": 45.5,
      "step": 195
    },
    {
      "epoch": 1.3066666666666666,
      "grad_norm": 649.1126098632812,
      "learning_rate": 8e-06,
      "loss": 16.5,
      "step": 196
    },
    {
      "epoch": 1.3066666666666666,
      "eval_loss": 42.7400016784668,
      "eval_runtime": 14.1184,
      "eval_samples_per_second": 42.498,
      "eval_steps_per_second": 2.692,
      "step": 196
    },
    {
      "epoch": 1.3133333333333335,
      "grad_norm": 574.7779541015625,
      "learning_rate": 8e-06,
      "loss": 21.0,
      "step": 197
    },
    {
      "epoch": 1.32,
      "grad_norm": 495.6297912597656,
      "learning_rate": 8e-06,
      "loss": 30.125,
      "step": 198
    },
    {
      "epoch": 1.3266666666666667,
      "grad_norm": 738.1591796875,
      "learning_rate": 8e-06,
      "loss": 39.75,
      "step": 199
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 804.3622436523438,
      "learning_rate": 8e-06,
      "loss": 43.25,
      "step": 200
    },
    {
      "epoch": 1.3333333333333333,
      "eval_loss": 42.20333480834961,
      "eval_runtime": 13.8926,
      "eval_samples_per_second": 43.188,
      "eval_steps_per_second": 2.735,
      "step": 200
    },
    {
      "epoch": 1.34,
      "grad_norm": 437.511962890625,
      "learning_rate": 8e-06,
      "loss": 22.375,
      "step": 201
    },
    {
      "epoch": 1.3466666666666667,
      "grad_norm": 736.4844970703125,
      "learning_rate": 8e-06,
      "loss": 28.125,
      "step": 202
    },
    {
      "epoch": 1.3533333333333333,
      "grad_norm": 544.1652221679688,
      "learning_rate": 8e-06,
      "loss": 23.0,
      "step": 203
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 527.4322509765625,
      "learning_rate": 8e-06,
      "loss": 43.75,
      "step": 204
    },
    {
      "epoch": 1.3599999999999999,
      "eval_loss": 42.253334045410156,
      "eval_runtime": 14.0902,
      "eval_samples_per_second": 42.583,
      "eval_steps_per_second": 2.697,
      "step": 204
    },
    {
      "epoch": 1.3666666666666667,
      "grad_norm": 654.7947387695312,
      "learning_rate": 8e-06,
      "loss": 38.75,
      "step": 205
    },
    {
      "epoch": 1.3733333333333333,
      "grad_norm": 1016.6788330078125,
      "learning_rate": 8e-06,
      "loss": 65.5,
      "step": 206
    },
    {
      "epoch": 1.38,
      "grad_norm": 534.4085693359375,
      "learning_rate": 8e-06,
      "loss": 27.75,
      "step": 207
    },
    {
      "epoch": 1.3866666666666667,
      "grad_norm": 424.7646179199219,
      "learning_rate": 8e-06,
      "loss": 29.875,
      "step": 208
    },
    {
      "epoch": 1.3866666666666667,
      "eval_loss": 42.05666732788086,
      "eval_runtime": 14.0167,
      "eval_samples_per_second": 42.806,
      "eval_steps_per_second": 2.711,
      "step": 208
    },
    {
      "epoch": 1.3933333333333333,
      "grad_norm": 744.6865844726562,
      "learning_rate": 8e-06,
      "loss": 37.75,
      "step": 209
    },
    {
      "epoch": 1.4,
      "grad_norm": 815.8953857421875,
      "learning_rate": 8e-06,
      "loss": 33.75,
      "step": 210
    },
    {
      "epoch": 1.4066666666666667,
      "grad_norm": 419.6083068847656,
      "learning_rate": 8e-06,
      "loss": 23.875,
      "step": 211
    },
    {
      "epoch": 1.4133333333333333,
      "grad_norm": 726.0816040039062,
      "learning_rate": 8e-06,
      "loss": 45.5,
      "step": 212
    },
    {
      "epoch": 1.4133333333333333,
      "eval_loss": 42.76499938964844,
      "eval_runtime": 14.0872,
      "eval_samples_per_second": 42.592,
      "eval_steps_per_second": 2.697,
      "step": 212
    },
    {
      "epoch": 1.42,
      "grad_norm": 779.4763793945312,
      "learning_rate": 8e-06,
      "loss": 28.0,
      "step": 213
    },
    {
      "epoch": 1.4266666666666667,
      "grad_norm": 564.8231201171875,
      "learning_rate": 8e-06,
      "loss": 28.0,
      "step": 214
    },
    {
      "epoch": 1.4333333333333333,
      "grad_norm": 519.6588745117188,
      "learning_rate": 8e-06,
      "loss": 25.5,
      "step": 215
    },
    {
      "epoch": 1.44,
      "grad_norm": 1471.1177978515625,
      "learning_rate": 8e-06,
      "loss": 71.0,
      "step": 216
    },
    {
      "epoch": 1.44,
      "eval_loss": 42.62666702270508,
      "eval_runtime": 13.9649,
      "eval_samples_per_second": 42.965,
      "eval_steps_per_second": 2.721,
      "step": 216
    },
    {
      "epoch": 1.4466666666666668,
      "grad_norm": 715.6283569335938,
      "learning_rate": 8e-06,
      "loss": 33.0,
      "step": 217
    },
    {
      "epoch": 1.4533333333333334,
      "grad_norm": 750.1510009765625,
      "learning_rate": 8e-06,
      "loss": 40.5,
      "step": 218
    },
    {
      "epoch": 1.46,
      "grad_norm": 2391.681396484375,
      "learning_rate": 8e-06,
      "loss": 59.5,
      "step": 219
    },
    {
      "epoch": 1.4666666666666668,
      "grad_norm": 751.0189819335938,
      "learning_rate": 8e-06,
      "loss": 27.25,
      "step": 220
    },
    {
      "epoch": 1.4666666666666668,
      "eval_loss": 42.393333435058594,
      "eval_runtime": 13.8891,
      "eval_samples_per_second": 43.199,
      "eval_steps_per_second": 2.736,
      "step": 220
    },
    {
      "epoch": 1.4733333333333334,
      "grad_norm": 1169.2291259765625,
      "learning_rate": 8e-06,
      "loss": 56.5,
      "step": 221
    },
    {
      "epoch": 1.48,
      "grad_norm": 712.3662719726562,
      "learning_rate": 8e-06,
      "loss": 40.25,
      "step": 222
    },
    {
      "epoch": 1.4866666666666668,
      "grad_norm": 358.99072265625,
      "learning_rate": 8e-06,
      "loss": 13.9375,
      "step": 223
    },
    {
      "epoch": 1.4933333333333334,
      "grad_norm": 660.1571655273438,
      "learning_rate": 8e-06,
      "loss": 22.875,
      "step": 224
    },
    {
      "epoch": 1.4933333333333334,
      "eval_loss": 41.891666412353516,
      "eval_runtime": 14.0191,
      "eval_samples_per_second": 42.799,
      "eval_steps_per_second": 2.711,
      "step": 224
    },
    {
      "epoch": 1.5,
      "grad_norm": 522.0973510742188,
      "learning_rate": 8e-06,
      "loss": 30.5,
      "step": 225
    },
    {
      "epoch": 1.5066666666666668,
      "grad_norm": 585.4752807617188,
      "learning_rate": 8e-06,
      "loss": 26.375,
      "step": 226
    },
    {
      "epoch": 1.5133333333333332,
      "grad_norm": 496.48968505859375,
      "learning_rate": 8e-06,
      "loss": 15.3125,
      "step": 227
    },
    {
      "epoch": 1.52,
      "grad_norm": 418.7239990234375,
      "learning_rate": 8e-06,
      "loss": 28.875,
      "step": 228
    },
    {
      "epoch": 1.52,
      "eval_loss": 41.709999084472656,
      "eval_runtime": 13.9132,
      "eval_samples_per_second": 43.124,
      "eval_steps_per_second": 2.731,
      "step": 228
    },
    {
      "epoch": 1.5266666666666666,
      "grad_norm": 525.1975708007812,
      "learning_rate": 8e-06,
      "loss": 19.25,
      "step": 229
    },
    {
      "epoch": 1.5333333333333332,
      "grad_norm": 441.6407165527344,
      "learning_rate": 8e-06,
      "loss": 32.75,
      "step": 230
    },
    {
      "epoch": 1.54,
      "grad_norm": 388.2337951660156,
      "learning_rate": 8e-06,
      "loss": 21.5,
      "step": 231
    },
    {
      "epoch": 1.5466666666666666,
      "grad_norm": 516.455322265625,
      "learning_rate": 8e-06,
      "loss": 26.625,
      "step": 232
    },
    {
      "epoch": 1.5466666666666666,
      "eval_loss": 41.84000015258789,
      "eval_runtime": 14.1543,
      "eval_samples_per_second": 42.39,
      "eval_steps_per_second": 2.685,
      "step": 232
    },
    {
      "epoch": 1.5533333333333332,
      "grad_norm": 459.5027770996094,
      "learning_rate": 8e-06,
      "loss": 35.25,
      "step": 233
    },
    {
      "epoch": 1.56,
      "grad_norm": 626.3286743164062,
      "learning_rate": 8e-06,
      "loss": 30.25,
      "step": 234
    },
    {
      "epoch": 1.5666666666666667,
      "grad_norm": 344.39215087890625,
      "learning_rate": 8e-06,
      "loss": 22.75,
      "step": 235
    },
    {
      "epoch": 1.5733333333333333,
      "grad_norm": 344.9018859863281,
      "learning_rate": 8e-06,
      "loss": 19.75,
      "step": 236
    },
    {
      "epoch": 1.5733333333333333,
      "eval_loss": 41.154998779296875,
      "eval_runtime": 13.8125,
      "eval_samples_per_second": 43.439,
      "eval_steps_per_second": 2.751,
      "step": 236
    },
    {
      "epoch": 1.58,
      "grad_norm": 299.53411865234375,
      "learning_rate": 8e-06,
      "loss": 16.625,
      "step": 237
    },
    {
      "epoch": 1.5866666666666667,
      "grad_norm": 584.431884765625,
      "learning_rate": 8e-06,
      "loss": 42.75,
      "step": 238
    },
    {
      "epoch": 1.5933333333333333,
      "grad_norm": 404.21429443359375,
      "learning_rate": 8e-06,
      "loss": 23.0,
      "step": 239
    },
    {
      "epoch": 1.6,
      "grad_norm": 396.77545166015625,
      "learning_rate": 8e-06,
      "loss": 18.625,
      "step": 240
    },
    {
      "epoch": 1.6,
      "eval_loss": 41.682498931884766,
      "eval_runtime": 13.8539,
      "eval_samples_per_second": 43.309,
      "eval_steps_per_second": 2.743,
      "step": 240
    },
    {
      "epoch": 1.6066666666666667,
      "grad_norm": 649.4096069335938,
      "learning_rate": 8e-06,
      "loss": 44.25,
      "step": 241
    },
    {
      "epoch": 1.6133333333333333,
      "grad_norm": 672.6283569335938,
      "learning_rate": 8e-06,
      "loss": 27.75,
      "step": 242
    },
    {
      "epoch": 1.62,
      "grad_norm": 797.11767578125,
      "learning_rate": 8e-06,
      "loss": 57.0,
      "step": 243
    },
    {
      "epoch": 1.6266666666666667,
      "grad_norm": 1030.7757568359375,
      "learning_rate": 8e-06,
      "loss": 53.25,
      "step": 244
    },
    {
      "epoch": 1.6266666666666667,
      "eval_loss": 41.94166564941406,
      "eval_runtime": 13.9657,
      "eval_samples_per_second": 42.962,
      "eval_steps_per_second": 2.721,
      "step": 244
    },
    {
      "epoch": 1.6333333333333333,
      "grad_norm": 959.9500732421875,
      "learning_rate": 8e-06,
      "loss": 46.5,
      "step": 245
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 938.6585693359375,
      "learning_rate": 8e-06,
      "loss": 49.5,
      "step": 246
    },
    {
      "epoch": 1.6466666666666665,
      "grad_norm": 356.06634521484375,
      "learning_rate": 8e-06,
      "loss": 20.375,
      "step": 247
    },
    {
      "epoch": 1.6533333333333333,
      "grad_norm": 1093.3486328125,
      "learning_rate": 8e-06,
      "loss": 62.25,
      "step": 248
    },
    {
      "epoch": 1.6533333333333333,
      "eval_loss": 42.46666717529297,
      "eval_runtime": 13.7493,
      "eval_samples_per_second": 43.638,
      "eval_steps_per_second": 2.764,
      "step": 248
    },
    {
      "epoch": 1.6600000000000001,
      "grad_norm": 809.90869140625,
      "learning_rate": 8e-06,
      "loss": 32.5,
      "step": 249
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 628.287109375,
      "learning_rate": 8e-06,
      "loss": 31.25,
      "step": 250
    },
    {
      "epoch": 1.6733333333333333,
      "grad_norm": 422.34368896484375,
      "learning_rate": 8e-06,
      "loss": 24.875,
      "step": 251
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 673.9088745117188,
      "learning_rate": 8e-06,
      "loss": 30.25,
      "step": 252
    },
    {
      "epoch": 1.6800000000000002,
      "eval_loss": 42.02000045776367,
      "eval_runtime": 13.8804,
      "eval_samples_per_second": 43.226,
      "eval_steps_per_second": 2.738,
      "step": 252
    },
    {
      "epoch": 1.6866666666666665,
      "grad_norm": 677.521240234375,
      "learning_rate": 8e-06,
      "loss": 26.875,
      "step": 253
    },
    {
      "epoch": 1.6933333333333334,
      "grad_norm": 529.0662841796875,
      "learning_rate": 8e-06,
      "loss": 26.25,
      "step": 254
    },
    {
      "epoch": 1.7,
      "grad_norm": 704.59130859375,
      "learning_rate": 8e-06,
      "loss": 26.375,
      "step": 255
    },
    {
      "epoch": 1.7066666666666666,
      "grad_norm": 414.4977722167969,
      "learning_rate": 8e-06,
      "loss": 16.75,
      "step": 256
    },
    {
      "epoch": 1.7066666666666666,
      "eval_loss": 40.67166519165039,
      "eval_runtime": 13.865,
      "eval_samples_per_second": 43.275,
      "eval_steps_per_second": 2.741,
      "step": 256
    },
    {
      "epoch": 1.7133333333333334,
      "grad_norm": 465.0076904296875,
      "learning_rate": 8e-06,
      "loss": 22.5,
      "step": 257
    },
    {
      "epoch": 1.72,
      "grad_norm": 563.084228515625,
      "learning_rate": 8e-06,
      "loss": 32.5,
      "step": 258
    },
    {
      "epoch": 1.7266666666666666,
      "grad_norm": 540.7633056640625,
      "learning_rate": 8e-06,
      "loss": 17.0,
      "step": 259
    },
    {
      "epoch": 1.7333333333333334,
      "grad_norm": 370.1744384765625,
      "learning_rate": 8e-06,
      "loss": 29.5,
      "step": 260
    },
    {
      "epoch": 1.7333333333333334,
      "eval_loss": 40.15583419799805,
      "eval_runtime": 13.8405,
      "eval_samples_per_second": 43.351,
      "eval_steps_per_second": 2.746,
      "step": 260
    },
    {
      "epoch": 1.74,
      "grad_norm": 542.0076904296875,
      "learning_rate": 8e-06,
      "loss": 32.0,
      "step": 261
    },
    {
      "epoch": 1.7466666666666666,
      "grad_norm": 4835.6474609375,
      "learning_rate": 8e-06,
      "loss": 109.5,
      "step": 262
    },
    {
      "epoch": 1.7533333333333334,
      "grad_norm": 719.10546875,
      "learning_rate": 8e-06,
      "loss": 16.5,
      "step": 263
    },
    {
      "epoch": 1.76,
      "grad_norm": 439.03472900390625,
      "learning_rate": 8e-06,
      "loss": 23.0,
      "step": 264
    },
    {
      "epoch": 1.76,
      "eval_loss": 40.380001068115234,
      "eval_runtime": 14.1864,
      "eval_samples_per_second": 42.294,
      "eval_steps_per_second": 2.679,
      "step": 264
    },
    {
      "epoch": 1.7666666666666666,
      "grad_norm": 382.4846496582031,
      "learning_rate": 8e-06,
      "loss": 22.25,
      "step": 265
    },
    {
      "epoch": 1.7733333333333334,
      "grad_norm": 707.7985229492188,
      "learning_rate": 8e-06,
      "loss": 41.75,
      "step": 266
    },
    {
      "epoch": 1.78,
      "grad_norm": 812.57080078125,
      "learning_rate": 8e-06,
      "loss": 43.25,
      "step": 267
    },
    {
      "epoch": 1.7866666666666666,
      "grad_norm": 457.22088623046875,
      "learning_rate": 8e-06,
      "loss": 20.75,
      "step": 268
    },
    {
      "epoch": 1.7866666666666666,
      "eval_loss": 40.2599983215332,
      "eval_runtime": 14.2095,
      "eval_samples_per_second": 42.225,
      "eval_steps_per_second": 2.674,
      "step": 268
    },
    {
      "epoch": 1.7933333333333334,
      "grad_norm": 381.2677307128906,
      "learning_rate": 8e-06,
      "loss": 20.625,
      "step": 269
    },
    {
      "epoch": 1.8,
      "grad_norm": 403.43475341796875,
      "learning_rate": 8e-06,
      "loss": 15.8125,
      "step": 270
    },
    {
      "epoch": 1.8066666666666666,
      "grad_norm": 414.9839172363281,
      "learning_rate": 8e-06,
      "loss": 23.125,
      "step": 271
    },
    {
      "epoch": 1.8133333333333335,
      "grad_norm": 385.1738586425781,
      "learning_rate": 8e-06,
      "loss": 20.0,
      "step": 272
    },
    {
      "epoch": 1.8133333333333335,
      "eval_loss": 39.874168395996094,
      "eval_runtime": 13.7431,
      "eval_samples_per_second": 43.658,
      "eval_steps_per_second": 2.765,
      "step": 272
    },
    {
      "epoch": 1.8199999999999998,
      "grad_norm": 516.9326171875,
      "learning_rate": 8e-06,
      "loss": 43.75,
      "step": 273
    },
    {
      "epoch": 1.8266666666666667,
      "grad_norm": 513.8104858398438,
      "learning_rate": 8e-06,
      "loss": 43.25,
      "step": 274
    },
    {
      "epoch": 1.8333333333333335,
      "grad_norm": 456.374755859375,
      "learning_rate": 8e-06,
      "loss": 24.875,
      "step": 275
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 615.9887084960938,
      "learning_rate": 8e-06,
      "loss": 31.375,
      "step": 276
    },
    {
      "epoch": 1.8399999999999999,
      "eval_loss": 39.8033332824707,
      "eval_runtime": 13.7708,
      "eval_samples_per_second": 43.571,
      "eval_steps_per_second": 2.759,
      "step": 276
    },
    {
      "epoch": 1.8466666666666667,
      "grad_norm": 316.46661376953125,
      "learning_rate": 8e-06,
      "loss": 19.75,
      "step": 277
    },
    {
      "epoch": 1.8533333333333335,
      "grad_norm": 341.5957946777344,
      "learning_rate": 8e-06,
      "loss": 22.875,
      "step": 278
    },
    {
      "epoch": 1.8599999999999999,
      "grad_norm": 955.9845581054688,
      "learning_rate": 8e-06,
      "loss": 64.0,
      "step": 279
    },
    {
      "epoch": 1.8666666666666667,
      "grad_norm": 521.8233642578125,
      "learning_rate": 8e-06,
      "loss": 15.875,
      "step": 280
    },
    {
      "epoch": 1.8666666666666667,
      "eval_loss": 39.74166488647461,
      "eval_runtime": 14.0095,
      "eval_samples_per_second": 42.828,
      "eval_steps_per_second": 2.712,
      "step": 280
    },
    {
      "epoch": 1.8733333333333333,
      "grad_norm": 707.8194580078125,
      "learning_rate": 8e-06,
      "loss": 48.75,
      "step": 281
    },
    {
      "epoch": 1.88,
      "grad_norm": 345.75933837890625,
      "learning_rate": 8e-06,
      "loss": 17.125,
      "step": 282
    },
    {
      "epoch": 1.8866666666666667,
      "grad_norm": 410.3202209472656,
      "learning_rate": 8e-06,
      "loss": 30.75,
      "step": 283
    },
    {
      "epoch": 1.8933333333333333,
      "grad_norm": 431.812255859375,
      "learning_rate": 8e-06,
      "loss": 26.0,
      "step": 284
    },
    {
      "epoch": 1.8933333333333333,
      "eval_loss": 39.561668395996094,
      "eval_runtime": 13.7302,
      "eval_samples_per_second": 43.699,
      "eval_steps_per_second": 2.768,
      "step": 284
    },
    {
      "epoch": 1.9,
      "grad_norm": 405.07183837890625,
      "learning_rate": 8e-06,
      "loss": 31.375,
      "step": 285
    },
    {
      "epoch": 1.9066666666666667,
      "grad_norm": 359.4562072753906,
      "learning_rate": 8e-06,
      "loss": 22.625,
      "step": 286
    },
    {
      "epoch": 1.9133333333333333,
      "grad_norm": 345.4156494140625,
      "learning_rate": 8e-06,
      "loss": 23.75,
      "step": 287
    },
    {
      "epoch": 1.92,
      "grad_norm": 1122.845947265625,
      "learning_rate": 8e-06,
      "loss": 46.0,
      "step": 288
    },
    {
      "epoch": 1.92,
      "eval_loss": 39.93083190917969,
      "eval_runtime": 14.0901,
      "eval_samples_per_second": 42.583,
      "eval_steps_per_second": 2.697,
      "step": 288
    },
    {
      "epoch": 1.9266666666666667,
      "grad_norm": 445.7954406738281,
      "learning_rate": 8e-06,
      "loss": 27.875,
      "step": 289
    },
    {
      "epoch": 1.9333333333333333,
      "grad_norm": 392.11309814453125,
      "learning_rate": 8e-06,
      "loss": 22.25,
      "step": 290
    },
    {
      "epoch": 1.94,
      "grad_norm": 451.3773193359375,
      "learning_rate": 8e-06,
      "loss": 28.125,
      "step": 291
    },
    {
      "epoch": 1.9466666666666668,
      "grad_norm": 498.8022155761719,
      "learning_rate": 8e-06,
      "loss": 21.625,
      "step": 292
    },
    {
      "epoch": 1.9466666666666668,
      "eval_loss": 39.160831451416016,
      "eval_runtime": 13.8909,
      "eval_samples_per_second": 43.194,
      "eval_steps_per_second": 2.736,
      "step": 292
    },
    {
      "epoch": 1.9533333333333334,
      "grad_norm": 331.9346923828125,
      "learning_rate": 8e-06,
      "loss": 18.375,
      "step": 293
    },
    {
      "epoch": 1.96,
      "grad_norm": 567.1062622070312,
      "learning_rate": 8e-06,
      "loss": 22.5,
      "step": 294
    },
    {
      "epoch": 1.9666666666666668,
      "grad_norm": 349.5548095703125,
      "learning_rate": 8e-06,
      "loss": 20.5,
      "step": 295
    },
    {
      "epoch": 1.9733333333333334,
      "grad_norm": 411.79302978515625,
      "learning_rate": 8e-06,
      "loss": 31.625,
      "step": 296
    },
    {
      "epoch": 1.9733333333333334,
      "eval_loss": 39.30416488647461,
      "eval_runtime": 13.9494,
      "eval_samples_per_second": 43.013,
      "eval_steps_per_second": 2.724,
      "step": 296
    },
    {
      "epoch": 1.98,
      "grad_norm": 596.783203125,
      "learning_rate": 8e-06,
      "loss": 39.0,
      "step": 297
    },
    {
      "epoch": 1.9866666666666668,
      "grad_norm": 520.30322265625,
      "learning_rate": 8e-06,
      "loss": 34.75,
      "step": 298
    },
    {
      "epoch": 1.9933333333333332,
      "grad_norm": 659.2920532226562,
      "learning_rate": 8e-06,
      "loss": 45.5,
      "step": 299
    },
    {
      "epoch": 2.0,
      "grad_norm": 1693.0174560546875,
      "learning_rate": 8e-06,
      "loss": 94.0,
      "step": 300
    },
    {
      "epoch": 2.0,
      "eval_loss": 39.80666732788086,
      "eval_runtime": 14.0341,
      "eval_samples_per_second": 42.753,
      "eval_steps_per_second": 2.708,
      "step": 300
    },
    {
      "epoch": 2.0,
      "step": 300,
      "total_flos": 1.5019856063627264e+16,
      "train_loss": 60.49791666666667,
      "train_runtime": 10370.732,
      "train_samples_per_second": 0.463,
      "train_steps_per_second": 0.029
    }
  ],
  "logging_steps": 1.0,
  "max_steps": 300,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 4,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.5019856063627264e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
